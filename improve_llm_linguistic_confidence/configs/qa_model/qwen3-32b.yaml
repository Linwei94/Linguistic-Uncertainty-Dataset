name: Qwen3-32B
model_name: Qwen/Qwen3-32B
temperature: 0.6
top_p: 0.95
top_k: 20
min_p: 0.0
enable_thinking: false
max_tokens: 1024
tokenize_output: false
add_generation_prompt: true
tensor_parallel_size: 1
gpu_memory_utilization: 0.9
disable_log_stats: true
trust_remote_code: true
dtype: auto
task: sample # ['sample' -> vllm generate response, 'train' -> base model for training]